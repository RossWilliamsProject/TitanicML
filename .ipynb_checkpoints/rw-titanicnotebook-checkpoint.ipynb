{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The \"Titanic\" Project**\n",
    "\n",
    "## *Contents*\n",
    "\n",
    "1) Problem Analysis and Definition\n",
    "\n",
    "2) Data \"Collection\"\n",
    "\n",
    "3) Light Data Analysis\n",
    "\n",
    "3) Data Cleaning\n",
    "\n",
    "4) Data Transformation\n",
    "\n",
    "5) Data Modelling\n",
    "\n",
    "6) Results Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem Analysis and Definition**\n",
    "\n",
    "Understanding the history and context of the data allows for a better analysis.\n",
    "The data set covers the fate of the passengers on the Titanic, a ship that sunk after hitting an iceburg. \n",
    "The data provided consists of a subset of the passengers on board the ship (891 out of 2240), \n",
    "split into the following two groups, \n",
    "1) A set for testing (\"test.csv\" - which doesnt contain details of the passengers survival) <br>\n",
    "2) A set for training (\"train.csv\" - which does contain details of the passengers survival). <br>\n",
    "\n",
    "The data contains several fields about each passenger (alongside the key detail of whether they lived or not)\n",
    "such as their age, information about their family, their social class, and so on. \n",
    "The aim of this project is to create a model to predict a passengers survival using this given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data \"Collection\"**\n",
    "\n",
    "Importing the correct modules for later in project (including visualisation and modelling modules)<br>\n",
    "The final code here outputs the input files from kaggle (datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:08.791465Z",
     "iopub.status.busy": "2022-08-12T13:43:08.791019Z",
     "iopub.status.idle": "2022-08-12T13:43:08.802866Z",
     "shell.execute_reply": "2022-08-12T13:43:08.801794Z",
     "shell.execute_reply.started": "2022-08-12T13:43:08.791430Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This is the code given by default by kaggle for the competition - it has been edited in some places\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Default Imports\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Added Imports for Visualisation\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# This is the code given by default by kaggle for the competition - it has been edited in some places\n",
    "\n",
    "# Default Imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Added Imports for Visualisation\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Added Imports for Modelling/ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Default given code to output input files from Kaggle\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below imports the data from the given CSVs into data frames.<br>\n",
    "Datasets are also \"combined\" (joined by column) so that this pointer can be used to perform transformative actions on both datasets at once later on in the code (eg: changing column names of both in one line of code).\n",
    "<br><br>\n",
    "As can be seen by printing each of the column headings for both datasets, the only current difference is the lack of \"Suvived\" attribute for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:09.239387Z",
     "iopub.status.busy": "2022-08-12T13:43:09.238776Z",
     "iopub.status.idle": "2022-08-12T13:43:09.258516Z",
     "shell.execute_reply": "2022-08-12T13:43:09.257534Z",
     "shell.execute_reply.started": "2022-08-12T13:43:09.239343Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the data frames from the provided CSVs\n",
    "training_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "testing_data = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "\n",
    "# Combined into a list, in order to iterate through later when changing both data frames at once\n",
    "combined_datasets = [training_data, testing_data]\n",
    "\n",
    "print(training_data.columns.values)\n",
    "print(testing_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Light Data Analysis**\n",
    "In this section, I will inspect whether the data is catagorical or numerical - as this will change how we analyse the data at first. <br>\n",
    "This can be seen by inspecting the datas head and analysing the values carefully to ensure their data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:09.561418Z",
     "iopub.status.busy": "2022-08-12T13:43:09.560062Z",
     "iopub.status.idle": "2022-08-12T13:43:09.580757Z",
     "shell.execute_reply": "2022-08-12T13:43:09.579293Z",
     "shell.execute_reply.started": "2022-08-12T13:43:09.561364Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen by the snippet of the data frame above, it is obvious which data is catagorical and numerical. These two sections will be explored differently - as catagorical datatypes cannot be analysed using popular visualisations such as histograms <br><br>\n",
    "***Catagorical Attributes***\n",
    "- Survived (Boolean, Catagorical)\n",
    "- Sex (Boolean, Catagorical)\n",
    "- Embarked (Char, Catagorical)\n",
    "- Pclass (Int, Ordinal) <br>\n",
    "\n",
    "***Numerical Attributes***\n",
    "- Age (Int)\n",
    "- Fare (Float)\n",
    "- SibSp (Int)\n",
    "- Parch (Int)\n",
    "\n",
    "***Mixed DataTypes***\n",
    "- Ticket (Mostly Ints, some with a leading String)\n",
    "- Cabin (Int with leading Char) <br>\n",
    "\n",
    "Mixed datatypes make analysing and exploring those datatypes more complex. To better analyse and compare this data, mixed datatypes should be sorted into catagories (such as taking only the leading letter for each cabin number) or transformed into pure ints (such as  removing leading strings from the ticket, leaving only the integer to fit the format of most of the tickets).\n",
    "<br>\n",
    "Before visualising or cleaning the now untransformed data, I will use the pandas info() and describe() functions to get a general idea about the data to raise some questions, which in asnwering will allow for a greater understanding of the data, and therefore (hopefully) a better prepared dataframe for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:09.891242Z",
     "iopub.status.busy": "2022-08-12T13:43:09.890317Z",
     "iopub.status.idle": "2022-08-12T13:43:09.912871Z",
     "shell.execute_reply": "2022-08-12T13:43:09.911883Z",
     "shell.execute_reply.started": "2022-08-12T13:43:09.891204Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data.info()\n",
    "print(\".........................................................\")\n",
    "testing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Info() Findings:**\n",
    "In general, training and testing null proportions for each variable are the same (data frames are comparable, as expected).\n",
    "Some interesting numbers to pay attention to are that there is very little na values for most data - making this a fairly complete data frame. The only variables with large null counts are age - which lacks almost 1/8t of the possibble values in both data sets, and cabin (wihch stores the cabin ID) - which lacks almost 3/4 of possible values. This makes using this variable much more complex - as the amount of values that will have to e approxmiated may be too large to accurately make up for the lost values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:10.209151Z",
     "iopub.status.busy": "2022-08-12T13:43:10.208390Z",
     "iopub.status.idle": "2022-08-12T13:43:10.246739Z",
     "shell.execute_reply": "2022-08-12T13:43:10.245683Z",
     "shell.execute_reply.started": "2022-08-12T13:43:10.209107Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:10.534825Z",
     "iopub.status.busy": "2022-08-12T13:43:10.533450Z",
     "iopub.status.idle": "2022-08-12T13:43:10.566019Z",
     "shell.execute_reply": "2022-08-12T13:43:10.564753Z",
     "shell.execute_reply.started": "2022-08-12T13:43:10.534782Z"
    }
   },
   "outputs": [],
   "source": [
    "testing_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:10.858337Z",
     "iopub.status.busy": "2022-08-12T13:43:10.857645Z",
     "iopub.status.idle": "2022-08-12T13:43:10.884256Z",
     "shell.execute_reply": "2022-08-12T13:43:10.883340Z",
     "shell.execute_reply.started": "2022-08-12T13:43:10.858301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Describe the dataframe object ('O')\n",
    "training_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe() Findings**\n",
    "These describe tables are useful for closely inspecting numerical data. <br>\n",
    "From these tables we can see that there is a large difference in the fair price paid (due to a large standard deviation), that the average age is around 30 years old (younger than the average age at the time, meaning that the ship was taken mostly by younger people), that around half of the people on the ship were travelling with siblings meaning a large amount of people were travelling with family, and including the number of parents or spouses, this number likely climbs even higher.<br>\n",
    "Using describe(include['O']) is used to get the description of the \"object\", which in this case, is the data frame itself. This shows how many unique values there are. As can be seen by inspecting the training data, there are large amount of ticket duplications, which is an issue that needs resolving as the ticket value is meant to be unique, however, this could be due to the existance of family tickets or something similar. As names are not dupliucated, we can safely assume that the entire passenger isnt being duplicated, just the ticket number. \n",
    "\n",
    "<br><br>\n",
    "**Basic Numeric Distributions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:11.058092Z",
     "iopub.status.busy": "2022-08-12T13:43:11.057689Z",
     "iopub.status.idle": "2022-08-12T13:43:11.952247Z",
     "shell.execute_reply": "2022-08-12T13:43:11.950712Z",
     "shell.execute_reply.started": "2022-08-12T13:43:11.058059Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split dataframe into catagorical and numerical numbers \n",
    "training_data_numerical = training_data[['Age','SibSp','Parch','Fare']]\n",
    "training_data_catagorical = training_data[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]\n",
    "\n",
    "# Display numerical variables using histograms to observe distributions\n",
    "for x in training_data_numerical.columns:\n",
    "    plt.hist(training_data_numerical[x])\n",
    "    plt.title(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Findings*\n",
    "- Age gives a nice normal distriution, will be useful untransformed \n",
    "- Siblings and parent numbers are similar distriutions, likely as families are travelling all together (increasing both at the same rate) - could consider combinging into one \"family\" attribute\n",
    "- Fare is a poor distribution, but seems to be in a shape that shows an exponential distribution - taking the log of this curve should give a normalised distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:11.955891Z",
     "iopub.status.busy": "2022-08-12T13:43:11.955083Z",
     "iopub.status.idle": "2022-08-12T13:43:12.224512Z",
     "shell.execute_reply": "2022-08-12T13:43:12.223317Z",
     "shell.execute_reply.started": "2022-08-12T13:43:11.955851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display a heatmap to display correlations between numerical variables\n",
    "sns.heatmap(training_data_numerical.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Findings* <br>\n",
    "This step is important to ensure that two attributes arent too strongly correlated - which could lead to Multicollinearity - in which the model too strongly advocates for something due to the two strongly correlating attributes compounding. \n",
    "- Age and siblings/spouses are inversely correlated - most likely because most data for this variable is for spouses - as adults are ore likely to be married the older they are\n",
    "- The strongest correlation is between \"parch\" and \"sibsp\" - which suggests that if the person has a spouse/sibling, they are also likely to have a parent/child also present. This follows the logic that entire families are present on the ship. \n",
    "- Other correlations are present, but not strong enough to be concerned about changing results negetively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:12.226711Z",
     "iopub.status.busy": "2022-08-12T13:43:12.226181Z",
     "iopub.status.idle": "2022-08-12T13:43:12.253997Z",
     "shell.execute_reply": "2022-08-12T13:43:12.252616Z",
     "shell.execute_reply.started": "2022-08-12T13:43:12.226663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a simple table that shows the link between variables and survival\n",
    "pd.pivot_table(training_data, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Findings* <br>\n",
    "- In general, younger people are more likely to survive \n",
    "- In general, people who paid more for their ticket are more likely to survive (significantly more likely)\n",
    "- In general, people with parents or children aboard are more likely to survive\n",
    "- In general, those with siblings or spouses aboard are more likely to not survive (although not significantly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:12.257995Z",
     "iopub.status.busy": "2022-08-12T13:43:12.256912Z",
     "iopub.status.idle": "2022-08-12T13:43:12.338075Z",
     "shell.execute_reply": "2022-08-12T13:43:12.336848Z",
     "shell.execute_reply.started": "2022-08-12T13:43:12.257945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display a series of tables which show the link between the catagories in catagorical variables and how survival is affected\n",
    "print(pd.pivot_table(training_data, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))\n",
    "print()\n",
    "print(pd.pivot_table(training_data, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))\n",
    "print()\n",
    "print(pd.pivot_table(training_data, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))\n",
    "print()\n",
    "print(pd.pivot_table(training_data, index = 'Survived', columns = 'Parch', values = 'Ticket' ,aggfunc ='count'))\n",
    "print()\n",
    "print(pd.pivot_table(training_data, index = 'Survived', columns = 'SibSp', values = 'Ticket' ,aggfunc ='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Findings* <br>\n",
    "- Class seems to have a large effect on those who survive, with nearly 2/3rds of 1st class passengers surviving, compared to only 1/4 of 3rd class.\n",
    "- Sex seems to also have a massive effect, there is a huge difference between the proportion of women who survived when compared to their male counterparts.\n",
    "- As shown before, family size seems to have a positive effect - whether thats have a spouse or having children. \n",
    "- Location embarked from does not seem to be statistically significant\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:12.340529Z",
     "iopub.status.busy": "2022-08-12T13:43:12.340045Z",
     "iopub.status.idle": "2022-08-12T13:43:12.856019Z",
     "shell.execute_reply": "2022-08-12T13:43:12.854650Z",
     "shell.execute_reply.started": "2022-08-12T13:43:12.340483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a palet bar chart which better shows how age effects survival\n",
    "g = sns.FacetGrid(training_data, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier analysis showed that the age of the passenger was not that significant (although younger people were slightly more likely to live) - this graph shows a mmuch better and easily understandable distribution. It shows that those who are young children are much more likely to survive. This distrubution also shows that for all other age groups, the survival and demise of passengers of any age is quite similar, showing that ignoring the skew provided by children, the chances of surviving are not heavily correlated to age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:12.858775Z",
     "iopub.status.busy": "2022-08-12T13:43:12.858285Z",
     "iopub.status.idle": "2022-08-12T13:43:12.874612Z",
     "shell.execute_reply": "2022-08-12T13:43:12.873070Z",
     "shell.execute_reply.started": "2022-08-12T13:43:12.858730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the first string from each name (which is the title)\n",
    "training_data['Title'] = training_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "# Display the number of each titles present\n",
    "training_data['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After listing the titles, we can see that the only statistically significant titles are Mr, Miss, Mrs and Master. These titles are already covered by the age and sex variables. The other titles, which could be significant, such as Countess, are covered by the class variable. This makes including the title obsolete. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:12.877896Z",
     "iopub.status.busy": "2022-08-12T13:43:12.877008Z",
     "iopub.status.idle": "2022-08-12T13:43:12.885970Z",
     "shell.execute_reply": "2022-08-12T13:43:12.884650Z",
     "shell.execute_reply.started": "2022-08-12T13:43:12.877847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing the Title variable\n",
    "training_data = training_data.drop(['Title'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "*Variables Included in Modelling*\n",
    "- Age\n",
    "- Class\n",
    "- Sex\n",
    "- Parch\n",
    "- SibSp\n",
    "- Fare\n",
    "\n",
    "*Variables NOT Included in Modelling*\n",
    "- Ticket\n",
    "    - Not relevant, including the fare tells the model everything needed to know about the ticket, alphanumerical string tells us nothing \n",
    "- Cabin\n",
    "    - Excluded due to a lack of compelte dataset, too many null values make using this variable too inaccurate\n",
    "- Embarked\n",
    "    - Does not appear to be statisically relevant, also not logically relevant. Titanic sank after all of these destinations were visited. \n",
    "- Name\n",
    "    - Excluding the title due to overlap between a passengers title, and their sex and class, the name is not relevant at all. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:12.890403Z",
     "iopub.status.busy": "2022-08-12T13:43:12.889236Z",
     "iopub.status.idle": "2022-08-12T13:43:13.153551Z",
     "shell.execute_reply": "2022-08-12T13:43:13.152326Z",
     "shell.execute_reply.started": "2022-08-12T13:43:12.890351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill NA values in variables with the averages to fill data set\n",
    "testing_data.Age = testing_data.Age.fillna(testing_data.Age.median())\n",
    "testing_data.Fare = testing_data.Fare.fillna(testing_data.Fare.mean())\n",
    "\n",
    "# Drop unneeded data\n",
    "testing_data = testing_data.drop(['Ticket'], axis=1)\n",
    "testing_data = testing_data.drop(['Cabin'], axis=1)\n",
    "testing_data = testing_data.drop(['Embarked'], axis=1)\n",
    "testing_data = testing_data.drop(['Name'], axis=1)\n",
    "\n",
    "# Translate fare prices into logorithic data to normalise and drop fare\n",
    "testing_data['LogFare'] = np.log(testing_data.Fare+1)\n",
    "testing_data['LogFare'].hist()\n",
    "testing_data = testing_data.drop(['Fare'], axis=1)\n",
    "\n",
    "# Replace catagorical sex strings with int values\n",
    "testing_data['Sex'] = testing_data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.155993Z",
     "iopub.status.busy": "2022-08-12T13:43:13.155081Z",
     "iopub.status.idle": "2022-08-12T13:43:13.365490Z",
     "shell.execute_reply": "2022-08-12T13:43:13.364081Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.155952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill NA values in variables with the averages to fill data set\n",
    "training_data.Age = training_data.Age.fillna(training_data.Age.median())\n",
    "training_data.Fare = training_data.Fare.fillna(training_data.Fare.mean())\n",
    "\n",
    "# Drop unneeded data\n",
    "training_data = training_data.drop(['Ticket'], axis=1)\n",
    "training_data = training_data.drop(['Cabin'], axis=1)\n",
    "training_data = training_data.drop(['Embarked'], axis=1)\n",
    "training_data = training_data.drop(['Name'], axis=1)\n",
    "\n",
    "# Translate fare prices into logorithic data to normalise and drop fare\n",
    "training_data['LogFare'] = np.log(training_data.Fare+1)\n",
    "training_data['LogFare'].hist()\n",
    "training_data = training_data.drop(['Fare'], axis=1)\n",
    "\n",
    "# Replace catagorical sex strings with int values\n",
    "training_data['Sex'] = training_data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.367997Z",
     "iopub.status.busy": "2022-08-12T13:43:13.367244Z",
     "iopub.status.idle": "2022-08-12T13:43:13.392064Z",
     "shell.execute_reply": "2022-08-12T13:43:13.391198Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.367952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confirm data changes\n",
    "training_data.info()\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.393825Z",
     "iopub.status.busy": "2022-08-12T13:43:13.393275Z",
     "iopub.status.idle": "2022-08-12T13:43:13.417366Z",
     "shell.execute_reply": "2022-08-12T13:43:13.416016Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.393793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confirm data changes\n",
    "testing_data.info()\n",
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Modelling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Preparation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.422179Z",
     "iopub.status.busy": "2022-08-12T13:43:13.421372Z",
     "iopub.status.idle": "2022-08-12T13:43:13.434640Z",
     "shell.execute_reply": "2022-08-12T13:43:13.433589Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.422130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seperate independant and dependant variables\n",
    "X_train = training_data[['Pclass','Sex','Age','SibSp','Parch','LogFare']]\n",
    "y_train = training_data['Survived']\n",
    "X_test = testing_data[['Pclass','Sex','Age','SibSp','Parch','LogFare']]\n",
    "\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model Usage***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.437627Z",
     "iopub.status.busy": "2022-08-12T13:43:13.436702Z",
     "iopub.status.idle": "2022-08-12T13:43:13.474056Z",
     "shell.execute_reply": "2022-08-12T13:43:13.472733Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.437544Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Model Use\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_predict = lr.predict(X_test)\n",
    "lrScore = round(lr.score(X_train, y_train), 2)\n",
    "print(lrScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.475876Z",
     "iopub.status.busy": "2022-08-12T13:43:13.475517Z",
     "iopub.status.idle": "2022-08-12T13:43:13.568553Z",
     "shell.execute_reply": "2022-08-12T13:43:13.567200Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.475845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Support Vector Classification Use\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_test = svc.predict(X_test)\n",
    "svcScore = round(svc.score(X_train, y_train), 2)\n",
    "print(svcScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.570501Z",
     "iopub.status.busy": "2022-08-12T13:43:13.570128Z",
     "iopub.status.idle": "2022-08-12T13:43:13.631742Z",
     "shell.execute_reply": "2022-08-12T13:43:13.630591Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.570465Z"
    }
   },
   "outputs": [],
   "source": [
    "# K Neighbors Classifier Use\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_test = knn.predict(X_test)\n",
    "knnScore = round(knn.score(X_train, y_train), 2)\n",
    "knnScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.634096Z",
     "iopub.status.busy": "2022-08-12T13:43:13.633362Z",
     "iopub.status.idle": "2022-08-12T13:43:13.652909Z",
     "shell.execute_reply": "2022-08-12T13:43:13.651644Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.634049Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gaussian Use\n",
    "gs = GaussianNB()\n",
    "gs.fit(X_train, y_train)\n",
    "y_test = gs.predict(X_test)\n",
    "gsScore = round(gs.score(X_train, y_train), 2)\n",
    "gsScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.654828Z",
     "iopub.status.busy": "2022-08-12T13:43:13.654498Z",
     "iopub.status.idle": "2022-08-12T13:43:13.959546Z",
     "shell.execute_reply": "2022-08-12T13:43:13.958350Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.654799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forrest Classifier Use\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_test = rf.predict(X_test)\n",
    "rf.score(X_train, y_train)\n",
    "rfScore = round(rf.score(X_train, y_train), 2)\n",
    "rfScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:13.961695Z",
     "iopub.status.busy": "2022-08-12T13:43:13.961294Z",
     "iopub.status.idle": "2022-08-12T13:43:13.979512Z",
     "shell.execute_reply": "2022-08-12T13:43:13.978633Z",
     "shell.execute_reply.started": "2022-08-12T13:43:13.961652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decision Tree Use\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_test = dt.predict(X_test)\n",
    "dtScore = round(dt.score(X_train, y_train), 2)\n",
    "dtScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears clearly that Random Forest Classifier and Decision Tree are the most accurate models used. \n",
    "I will choose to submit The Decision Tree model predictions, as the data set is small, and random forest is likely too complex for the predictions that are to be made- and therefore may overanalyse the data (as well as simply not being as efficient for the small task at hand)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T13:43:23.808152Z",
     "iopub.status.busy": "2022-08-12T13:43:23.807542Z",
     "iopub.status.idle": "2022-08-12T13:43:23.814982Z",
     "shell.execute_reply": "2022-08-12T13:43:23.813849Z",
     "shell.execute_reply.started": "2022-08-12T13:43:23.808119Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": testing_data[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission.csv', index =False)\n",
    "print(submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
